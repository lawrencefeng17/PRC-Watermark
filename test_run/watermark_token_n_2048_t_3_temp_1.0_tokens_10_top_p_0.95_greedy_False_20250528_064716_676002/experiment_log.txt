Experiment ID: watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False
Timestamp: 20250528_064716_676002
Parameters: {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'prompt': 'Test prompt', 'num_tokens': 10, 'n': 2048, 'temperature': 1.0, 'top_p': 0.95, 'greedy': False, 'methods': 'token', 'experiment_id': None, 'output_dir': 'test_run', 'fpr': 1e-05, 'prc_t': 3, 'debug': False, 'new': False}
Loading model...
Cleared CUDA cache after model loading.
Model loaded on cuda
Prompt: Test prompt
Setting up PRC keys for watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False
PRC keys set up
Saved key to test_run/watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False_20250528_064716_676002/watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False_key.pkl
Generation started at: 2025-05-28 06:47:21

=== Running Token Watermarking ===
Creating token watermarking model
Generating watermarked text (token method)
Warning: Plot file rejections_vs_index.png not found, skipping
Warning: Plot file rejection_rate_vs_entropy.png not found, skipping
Warning: Plot file bucket_0_distribution.png not found, skipping
Warning: Plot file bucket_1_distribution.png not found, skipping
Token generation completed in 1.77 seconds
Generated 10 tokens
Rejection rate: 0.0000
Match rate: 0.9000
Output text saved to test_run/watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False_20250528_064716_676002/text/token_output.txt
Detecting watermark...
Threshold: 689.6885582087334, Hamming weight: 1001.0
Detection result: False
Average pushforward entropy: 0.6462
Std dev pushforward entropy: 0.4357
Experiment completed at: 2025-05-28 06:47:23
Total duration: 0:00:01.786385

=== Experiment Summary ===

TOKEN Watermarking:
  Watermark detected: False
  Hamming weight: 1001.0 (threshold: 689.6885582087334)
  Rejection rate: 0.0000
  Match rate: 0.9000

Results saved to: test_run/watermark_token_n_2048_t_3_temp_1.0_tokens_10_top_p_0.95_greedy_False_20250528_064716_676002
