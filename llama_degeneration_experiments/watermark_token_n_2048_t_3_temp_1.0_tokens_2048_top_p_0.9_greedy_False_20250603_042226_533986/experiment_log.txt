Experiment ID: watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.9_greedy_False
Timestamp: 20250603_042226_533986
Parameters: {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'prompt': 'Write a thrilling story about a murder investigation in an old mansion.', 'num_tokens': 2048, 'n': 2048, 'temperature': 1.0, 'top_p': 0.9, 'greedy': False, 'methods': 'token', 'experiment_id': None, 'output_dir': '/home/lawrence/PRC-Watermark/llama_degeneration_experiments', 'fpr': 1e-05, 'prc_t': 3, 'debug': True, 'new': True}
Loading model...
Cleared CUDA cache after model loading.
Model loaded on cuda
Prompt: Write a thrilling story about a murder investigation in an old mansion.
Setting up PRC keys for watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.9_greedy_False
PRC keys set up
Saved key to /home/lawrence/PRC-Watermark/llama_degeneration_experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.9_greedy_False_20250603_042226_533986/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.9_greedy_False_key.pkl
Generation started at: 2025-06-03 04:22:31

=== Running Token Watermarking ===
Creating token watermarking model
Generating watermarked text (token method)
