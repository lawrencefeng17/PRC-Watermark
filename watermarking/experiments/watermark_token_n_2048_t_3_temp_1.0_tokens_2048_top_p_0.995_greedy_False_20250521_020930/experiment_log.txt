Experiment ID: watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
Timestamp: 20250521_020930
Parameters: {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'prompt': 'Write a thrilling story about a murder investigation in an old mansion.', 'num_tokens': 2048, 'n': 2048, 'temperature': 1.0, 'top_p': 0.995, 'greedy': False, 'methods': 'token', 'experiment_id': None, 'output_dir': 'experiments', 'fpr': 1e-05, 'prc_t': 3, 'debug': True, 'new': True}
Loading model...
Model loaded on cuda
Prompt: Write a thrilling story about a murder investigation in an old mansion.
Setting up PRC keys for watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
PRC keys set up
Saved key to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_020930/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_key.pkl
Generation started at: 2025-05-21 02:09:33

=== Running Token Watermarking ===
Creating token watermarking model
Generating watermarked text (token method)
Token generation completed in 64.93 seconds
Generated 2048 tokens
Rejection rate: 0.4233
Match rate: 0.5767
Output text saved to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_020930/text/token_output.txt
Average entropy for accepted tokens: 0.3174
Average entropy for rejected tokens: 0.1108
Detecting watermark...
Threshold: 689.6885582087334, Hamming weight: 990.0
Detection result: False
Experiment completed at: 2025-05-21 02:10:38
Total duration: 0:01:05.093935

=== Experiment Summary ===

TOKEN Watermarking:
  Watermark detected: False
  Hamming weight: 990.0 (threshold: 689.6885582087334)
  Rejection rate: 0.4233
  Match rate: 0.5767

Results saved to: experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_020930
