Experiment ID: watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
Timestamp: 20250521_012047
Parameters: {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'prompt': 'Write a thrilling story about a murder investigation in an old mansion.', 'num_tokens': 2048, 'n': 2048, 'temperature': 1.0, 'top_p': 0.995, 'greedy': False, 'methods': 'token', 'experiment_id': None, 'output_dir': 'experiments', 'fpr': 1e-05, 'prc_t': 3, 'debug': True, 'new': True}
Loading model...
Model loaded on cuda
Prompt: Write a thrilling story about a murder investigation in an old mansion.
Setting up PRC keys for watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
PRC keys set up
Saved key to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_012047/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_key.pkl
Generation started at: 2025-05-21 01:20:50

=== Running Token Watermarking ===
Creating token watermarking model
Generating watermarked text (token method)
Token generation completed in 64.16 seconds
Generated 2048 tokens
Rejection rate: 0.0874
Match rate: 0.9126
Output text saved to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_012047/text/token_output.txt
Average entropy for accepted tokens: 0.9187
Average entropy for rejected tokens: 0.3922
Detecting watermark...
Threshold: 689.6885582087334, Hamming weight: 497.0
Detection result: True
Experiment completed at: 2025-05-21 01:21:54
Total duration: 0:01:04.317844

=== Experiment Summary ===

TOKEN Watermarking:
  Watermark detected: True
  Hamming weight: 497.0 (threshold: 689.6885582087334)
  Rejection rate: 0.0874
  Match rate: 0.9126

Results saved to: experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_012047
