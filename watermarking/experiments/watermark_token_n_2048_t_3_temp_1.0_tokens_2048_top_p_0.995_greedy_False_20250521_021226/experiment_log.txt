Experiment ID: watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
Timestamp: 20250521_021226
Parameters: {'model_id': 'meta-llama/Llama-3.2-1B-Instruct', 'prompt': 'Write a thrilling story about a murder investigation in an old mansion.', 'num_tokens': 2048, 'n': 2048, 'temperature': 1.0, 'top_p': 0.995, 'greedy': False, 'methods': 'token', 'experiment_id': None, 'output_dir': 'experiments', 'fpr': 1e-05, 'prc_t': 3, 'debug': True, 'new': True}
Loading model...
Model loaded on cuda
Prompt: Write a thrilling story about a murder investigation in an old mansion.
Setting up PRC keys for watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False
PRC keys set up
Saved key to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_021226/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_key.pkl
Generation started at: 2025-05-21 02:12:29

=== Running Token Watermarking ===
Creating token watermarking model
Generating watermarked text (token method)
Token generation completed in 81.02 seconds
Generated 2048 tokens
Rejection rate: 0.0415
Match rate: 0.9585
Output text saved to experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_021226/text/token_output.txt
Average entropy for accepted tokens: 0.9701
Average entropy for rejected tokens: 0.3996
Detecting watermark...
Threshold: 689.6885582087334, Hamming weight: 318.0
Detection result: True
Experiment completed at: 2025-05-21 02:13:50
Total duration: 0:01:21.186226

=== Experiment Summary ===

TOKEN Watermarking:
  Watermark detected: True
  Hamming weight: 318.0 (threshold: 689.6885582087334)
  Rejection rate: 0.0415
  Match rate: 0.9585

Results saved to: experiments/watermark_token_n_2048_t_3_temp_1.0_tokens_2048_top_p_0.995_greedy_False_20250521_021226
