{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.prc import Encode, Decode, KeyGen\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, set_seed\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_huffman_tree(frequencies):\n",
    "    #using a dictionary instead of a heap\n",
    "    nodes = {symbol: {\"freq\": freq, \"left\": None, \"right\": None, \"symbol\": symbol} for symbol, freq in frequencies.items()}\n",
    "    while len(nodes) > 1:\n",
    "        #find two least frequent nodes\n",
    "        left_symbol, right_symbol = sorted(nodes, key=lambda symbol: nodes[symbol][\"freq\"])[:2]\n",
    "        left_node = nodes.pop(left_symbol)\n",
    "        right_node = nodes.pop(right_symbol)\n",
    "        new_node = {\"freq\": left_node[\"freq\"] + right_node[\"freq\"], \"left\": left_node, \"right\": right_node}\n",
    "        nodes[f\"{left_symbol}, {right_symbol}\"] = new_node\n",
    "\n",
    "    [(root_symbol, root_node)] = nodes.items()\n",
    "    return root_node\n",
    "\n",
    "def generate_huffman_codes(tree):\n",
    "    codes = {}\n",
    "    def traverse(node, current_code=\"\"):\n",
    "        if node[\"left\"] is None and node[\"right\"] is None:\n",
    "            # Store the code for the symbol, not the frequency\n",
    "            codes[node[\"symbol\"]] = current_code\n",
    "            return\n",
    "        traverse(node[\"left\"], current_code + \"0\")\n",
    "        traverse(node[\"right\"], current_code + \"1\")\n",
    "    traverse(tree)\n",
    "    return codes\n",
    "\n",
    "def huffman_encode(frequencies):\n",
    "  tree = build_huffman_tree(frequencies)\n",
    "  codes = generate_huffman_codes(tree)\n",
    "  encoding = {token: codes[token] for token, freq in frequencies.items()}\n",
    "  return encoding\n",
    "\n",
    "def huffman_decode(encoding, encoded_string):\n",
    "    decoding = {code: symbol for symbol, code in encoding.items()} # This line was correct\n",
    "    decoded_sequence = []\n",
    "    current_code = \"\"\n",
    "    for bit in encoded_string:\n",
    "        current_code += bit\n",
    "        if current_code in decoding:\n",
    "            decoded_sequence.append(decoding[current_code])\n",
    "            current_code = \"\"\n",
    "    return decoded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizedModel:\n",
    "    def __init__(self, original_model, encoding_key, decoding_key, n, tokenizer=None, frequencies=None, encoding=None, decoding=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            original_model: The original (non-binary) language model.\n",
    "            encoding_key: The key for the PRC encoding.\n",
    "            tokenizer: The tokenizer for the model.\n",
    "            frequencies: A dictionary mapping original tokens to frequencies.\n",
    "            encoding:  A dictionary mapping original tokens to binary strings (prefix-free).\n",
    "            decoding: A dictionary mapping binary strings to original tokens.\n",
    "        \"\"\"\n",
    "        self.original_model = original_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = next(original_model.parameters()).device\n",
    "        self.encoding_key = encoding_key\n",
    "        self.decoding_key = decoding_key\n",
    "        self.prc_codeword = (Encode(encoding_key) + 1) / 2 # convert to {0, 1}\n",
    "\n",
    "        assert len(self.prc_codeword) == n\n",
    "        self.n = n\n",
    "\n",
    "        self.prc_index = 0\n",
    "\n",
    "        assert frequencies is not None or (encoding is not None and decoding is not None)\n",
    "\n",
    "        if frequencies is not None:\n",
    "            self.generate_huffman_encoding(frequencies)\n",
    "        else:\n",
    "            self.encoding = encoding\n",
    "            self.decoding = decoding  # Corrected: This should be the *decoding* dict\n",
    "            \n",
    "        # Precompute prefix mappings for optimization\n",
    "        self._precompute_prefix_mappings()\n",
    "\n",
    "    def _precompute_prefix_mappings(self):\n",
    "        \"\"\"\n",
    "        Precompute mappings from prefixes to possible tokens for faster lookup.\n",
    "        This builds a dictionary mapping each possible prefix to the set of tokens\n",
    "        that could follow it.\n",
    "        \"\"\"\n",
    "        # Initialize prefix-to-tokens mapping\n",
    "        self.prefix_to_tokens = {}\n",
    "        \n",
    "        # For each token and its binary code\n",
    "        for token_id, code in self.encoding.items():\n",
    "            # Add all prefixes of this code to the mapping\n",
    "            for i in range(len(code) + 1):\n",
    "                prefix = code[:i]\n",
    "                if prefix not in self.prefix_to_tokens:\n",
    "                    self.prefix_to_tokens[prefix] = set()\n",
    "                self.prefix_to_tokens[prefix].add(token_id)\n",
    "                \n",
    "        # Convert sets to frozen sets for efficiency\n",
    "        self.prefix_to_tokens = {prefix: frozenset(tokens) for prefix, tokens in self.prefix_to_tokens.items()}\n",
    "        \n",
    "        # Create mapping from prefix + bit to new possible tokens\n",
    "        self.prefix_extension = {}\n",
    "        for prefix in self.prefix_to_tokens:\n",
    "            self.prefix_extension[(prefix, '0')] = frozenset(\n",
    "                token_id for token_id in self.prefix_to_tokens[prefix]\n",
    "                if len(self.encoding[token_id]) > len(prefix) and self.encoding[token_id][len(prefix):len(prefix)+1] == '0'\n",
    "            )\n",
    "            self.prefix_extension[(prefix, '1')] = frozenset(\n",
    "                token_id for token_id in self.prefix_to_tokens[prefix]\n",
    "                if len(self.encoding[token_id]) > len(prefix) and self.encoding[token_id][len(prefix):len(prefix)+1] == '1'\n",
    "            )\n",
    "\n",
    "    def generate_huffman_encoding(self, frequencies):\n",
    "        self.encoding = huffman_encode(frequencies)\n",
    "        self.decoding = {code: token_id for token_id, code in self.encoding.items()}\n",
    "        \n",
    "    def predict_binary_probs(self, original_token_probs, prefix):\n",
    "        \"\"\"\n",
    "        Optimized version that calculates the probability of the next bit being 0 or 1.\n",
    "        \n",
    "        For bit 0: sum probabilities of tokens whose encoding starts with prefix+'0'\n",
    "        For bit 1: sum probabilities of tokens whose encoding starts with prefix+'1'\n",
    "        \"\"\"\n",
    "        # Get tokens that could follow this prefix with a 0 or 1\n",
    "        prefix_plus_zero = (prefix, '0')\n",
    "        prefix_plus_one = (prefix, '1')\n",
    "        \n",
    "        # Get tokens that could follow this prefix with a 0\n",
    "        tokens_with_zero = self.prefix_extension.get(prefix_plus_zero, frozenset())\n",
    "        # Get tokens that could follow this prefix with a 1\n",
    "        tokens_with_one = self.prefix_extension.get(prefix_plus_one, frozenset())\n",
    "        \n",
    "        # If no possible continuations, return equal probabilities\n",
    "        if not tokens_with_zero and not tokens_with_one:\n",
    "            assert False\n",
    "        \n",
    "        # Calculate probability for bit '0'\n",
    "        prob_of_zero = sum(original_token_probs.get(token_id, 0) for token_id in tokens_with_zero)\n",
    "        # Calculate probability for bit '1'\n",
    "        prob_of_one = sum(original_token_probs.get(token_id, 0) for token_id in tokens_with_one)\n",
    "        \n",
    "        # Normalize to ensure they sum to 1\n",
    "        total = prob_of_zero + prob_of_one\n",
    "        if total > 0:\n",
    "            prob_of_zero /= total\n",
    "            prob_of_one /= total\n",
    "        else:\n",
    "            # If all tokens have zero probability, default to equal probabilities\n",
    "            prob_of_zero = 0.5\n",
    "            prob_of_one = 0.5\n",
    "        \n",
    "        prob_of_one = min(prob_of_one, 1.0)\n",
    "        # For efficiency, return both probabilities\n",
    "        return 1.0 - prob_of_one, prob_of_one\n",
    "\n",
    "    def sample_binary_token(self, x_i, hat_p_i):\n",
    "        \"\"\"\n",
    "        Samples a binary token from the biased probabilities.\n",
    "\n",
    "        x_i is the current index in the PRC codeword.\n",
    "        hat_p_i is the E[p] which specifies the distribution over the next binary token.\n",
    "        \"\"\"\n",
    "        if hat_p_i <= 0.5:\n",
    "            # t_i <- Ber(2x_i * hat_p_i)\n",
    "            return np.random.binomial(1, 2 * x_i * hat_p_i)\n",
    "        else:\n",
    "            # t_i <- Ber(1 - 2(1 - x_i)(1 - hat_p_i))\n",
    "            return np.random.binomial(1, 1 - 2 * (1 - x_i) * (1 - hat_p_i))\n",
    "\n",
    "    def watermarked_generate(self, prompt, num_bits):\n",
    "        \"\"\"\n",
    "        Generates text using the watermarked, binarized model.\n",
    "        Important: num_tokens is now the number of tokens in the *original* vocab.\n",
    "        Args:\n",
    "            num_tokens: the number of tokens *from the original vocabulary* we want to generate.\n",
    "        \"\"\"\n",
    "        binary_tokens = []\n",
    "        output_tokens = []\n",
    "        output_text = \"\"\n",
    "\n",
    "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(self.device) # Encode the prompt!\n",
    "\n",
    "\n",
    "        with tqdm(total=num_bits, desc=\"Generating bits\") as pbar:\n",
    "            while len(binary_tokens) < num_bits:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.original_model(input_ids=input_ids)\n",
    "                    logits = outputs.logits[0, -1, :]  # Get logits for the last token\n",
    "                    probs = torch.softmax(logits, dim=0)\n",
    "                    original_token_probs = {i: probs[i].item() for i in range(len(probs))}\n",
    "\n",
    "                prefix = \"\"\n",
    "                # loop until s becomes a valid encoding, and do not stop if eos_token is generated\n",
    "                while True:\n",
    "                    prob_of_zero, prob_of_one = self.predict_binary_probs(original_token_probs, prefix)\n",
    "                    \n",
    "                    # Sample bit using PRC watermarking\n",
    "                    x_i = self.prc_codeword[self.prc_index].item() \n",
    "                    next_bit = self.sample_binary_token(x_i, prob_of_one)\n",
    "                    binary_tokens.append(next_bit)\n",
    "                    self.prc_index += 1\n",
    "                    pbar.update(1)\n",
    "\n",
    "                    # if we've used all the bits in the PRC codeword, reset it\n",
    "                    if self.prc_index == len(self.prc_codeword):\n",
    "                        self.prc_index = 0\n",
    "                        self.prc_codeword = (Encode(self.encoding_key) + 1) / 2\n",
    "\n",
    "                    prefix += str(next_bit)\n",
    "\n",
    "                    if prefix in self.decoding:\n",
    "                        decoded_token_id = self.decoding[prefix] \n",
    "                        output_tokens.append(decoded_token_id)\n",
    "                        decoded_str = self.tokenizer.decode([decoded_token_id])\n",
    "                        input_ids = torch.cat([input_ids, torch.tensor([[decoded_token_id]]).to(self.device)], dim=-1)\n",
    "                        output_text += decoded_str\n",
    "                        break # Exit the inner loop\n",
    "\n",
    "                    if len(binary_tokens) >= num_bits:\n",
    "                        break\n",
    "                \n",
    "                if len(binary_tokens) >= num_bits:\n",
    "                    break\n",
    "\n",
    "        return output_tokens, output_text\n",
    "    \n",
    "    def detect_windows(self, watermarked_text):\n",
    "        \"\"\"\n",
    "        Detects if the provided text is watermarked, using PRC detection.\n",
    "        \"\"\"\n",
    "        # convert watermarked_text to binary string using encoding\n",
    "        watermarked_text_binary = ''.join([self.encoding[token_id] for token_id in watermarked_text])\n",
    "        watermarked_text_binary = torch.tensor([int(bit) for bit in watermarked_text_binary], dtype=float)\n",
    "        watermarked_text_binary = 2 * watermarked_text_binary - 1\n",
    "\n",
    "        # instead of checking all substrings, let's just check windows of size n\n",
    "        for i in range(0, len(watermarked_text_binary) - self.n + 1):\n",
    "            window = watermarked_text_binary[i:i+self.n]\n",
    "            if Decode(self.decoding_key, window) is not None:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def detect_hamming(self, watermarked_text):\n",
    "        \"\"\"\n",
    "        Detects if the provided text is watermarked, using hamming distance.\n",
    "        \"\"\"\n",
    "        # convert watermarked_text to binary string using encoding\n",
    "        watermarked_text_binary = ''.join([self.encoding[token_id] for token_id in watermarked_text])\n",
    "        watermarked_text_binary = torch.tensor([int(bit) for bit in watermarked_text_binary], dtype=float)\n",
    "        watermarked_text_binary = 2 * watermarked_text_binary - 1\n",
    "\n",
    "        # wt(Px) < (1/2 - r^(-1/4)) * r, output 1, where P is the parity check matrix\n",
    "        parity_check_matrix = self.decoding_key[1]\n",
    "        # compute Px\n",
    "        Px = parity_check_matrix @ watermarked_text_binary\n",
    "        # count the number of 1s in Px\n",
    "        num_1s = Px.sum().item()\n",
    "        # compute the hamming distance\n",
    "        hamming_distance = torch.sum(torch.abs(Px))\n",
    "        return hamming_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(vocab_size, exp_id, n, fpr, prc_t):\n",
    "    if not os.path.exists(f'keys/{exp_id}.pkl'):  # Generate watermark key for the first time and save it to a file\n",
    "        print(\"Generating PRC keys...\")\n",
    "        (encoding_key_ori, decoding_key_ori) = KeyGen(n, false_positive_rate=fpr, t=prc_t)  # Sample PRC keys\n",
    "        with open(f'keys/{exp_id}.pkl', 'wb') as f:  # Save the keys to a file\n",
    "            pickle.dump((encoding_key_ori, decoding_key_ori), f)\n",
    "        with open(f'keys/{exp_id}.pkl', 'rb') as f:  # Load the keys from a file\n",
    "            encoding_key, decoding_key = pickle.load(f)\n",
    "        assert encoding_key[0].all() == encoding_key_ori[0].all()\n",
    "    else:  # Or we can just load the keys from a file\n",
    "        print(f'Loading PRC keys from file keys/{exp_id}.pkl')\n",
    "        with open(f'keys/{exp_id}.pkl', 'rb') as f:\n",
    "            encoding_key, decoding_key = pickle.load(f)\n",
    "        print(f'Loaded PRC keys from file keys/{exp_id}.pkl')\n",
    "    return encoding_key, decoding_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(prompt='Tell me a fantastical story about a wizard.', test_num=10, model_id='meta-llama/Llama-3.2-1B-Instruct', inf_steps=50, nowm=0, fpr=1e-05, prc_t=3)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser('Args')\n",
    "parser.add_argument('--prompt', type=str, default='Tell me a fantastical story about a wizard.')\n",
    "parser.add_argument('--test_num', type=int, default=10)\n",
    "parser.add_argument('--model_id', type=str, default='meta-llama/Llama-3.2-1B-Instruct')\n",
    "# parser.add_argument('--dataset_id', type=str, default='databricks/databricks-dolly-15k')\n",
    "parser.add_argument('--inf_steps', type=int, default=50)\n",
    "parser.add_argument('--nowm', type=int, default=0)\n",
    "parser.add_argument('--fpr', type=float, default=0.00001)\n",
    "parser.add_argument('--prc_t', type=int, default=3)\n",
    "args = parser.parse_args([])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_cache_dir = '/home/lawrence/.cache/huggingface/hub'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "n = 2**11 # the length of a PRC codeword (for stable diffusion)\n",
    "test_num = args.test_num\n",
    "model_id = args.model_id\n",
    "nowm = args.nowm\n",
    "fpr = args.fpr\n",
    "prc_t = args.prc_t\n",
    "exp_id = f'binarize_num_{test_num}_steps_{args.inf_steps}_fpr_{fpr}_nowm_{nowm}_n_{n}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "    # Add padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "vocab_size = config.vocab_size\n",
    "eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Tell me a fantastical story about a wizard.\n",
      "Setting up PRC keys for binarize_num_10_steps_50_fpr_1e-05_nowm_0_n_2048\n",
      "Loading PRC keys from file keys/binarize_num_10_steps_50_fpr_1e-05_nowm_0_n_2048.pkl\n",
      "Loaded PRC keys from file keys/binarize_num_10_steps_50_fpr_1e-05_nowm_0_n_2048.pkl\n",
      "PRC keys set up\n",
      "Encoding loaded\n",
      "Binarized model loaded\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt\n",
    "prompt = args.prompt\n",
    "print(f\"Prompt: {prompt}\")\n",
    "\n",
    "# Get the encoding key\n",
    "print(f\"Setting up PRC keys for {exp_id}\")\n",
    "encoding_key, decoding_key = setup(vocab_size, exp_id, n, fpr, prc_t)\n",
    "print(f\"PRC keys set up\")\n",
    "\n",
    "if not os.path.exists(f'encoding_{exp_id}.pkl'):\n",
    "    token_counts = {token_id: 0 for token_id in range(vocab_size)}\n",
    "    with open(\"pride_and_prejudice.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "        example_corpus = f.readlines()\n",
    "    for sentence in example_corpus:\n",
    "        input_ids = tokenizer.encode(sentence)\n",
    "        for token_id in input_ids:\n",
    "            token_counts[token_id] += 1\n",
    "\n",
    "    encoding = huffman_encode(token_counts)\n",
    "    # save encoding to file\n",
    "    with open(f'encoding_{exp_id}.pkl', 'wb') as f:\n",
    "        pickle.dump(encoding, f)\n",
    "else:\n",
    "    with open(f'encoding_{exp_id}.pkl', 'rb') as f:\n",
    "        encoding = pickle.load(f)\n",
    "print(f\"Encoding loaded\")\n",
    "\n",
    "decoding = {code: token_id for token_id, code in encoding.items()}\n",
    "\n",
    "# Binarize the model\n",
    "binarized_model = BinarizedModel(\n",
    "    original_model=model,\n",
    "    encoding_key=encoding_key,\n",
    "    decoding_key=decoding_key,\n",
    "    n=n,\n",
    "    tokenizer=tokenizer,\n",
    "    encoding=encoding,\n",
    "    decoding=decoding)\n",
    "print(f\"Binarized model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating bits:   0%|                               | 0/2048 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating bits: 100%|████████████████████| 2048/2048 [04:46<00:00,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:  Zephyr, the Guardian of the Forest\n",
      "In the heart of a mystical realm, hidden from mortal eyes, stood the ancient forest of Elvendom. Its canopy of iridescent leaves and branches seemed to defy gravity as the wind whispered secrets to the trees. It was a place where magic soaked in like a fine wine, where the pulse of nature sustained civilizations and pulsed with an otherworldly energy.\n",
      "Here was where Zephyr, the Guardian of the Forest, resided. Zephyr's tale began over 800 years ago, when the world was young and still shrouded in darkness. With wild hair as golden as\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "output_tokens, output_text = binarized_model.watermarked_generate(prompt, num_bits=n)\n",
    "print(f\"Output text: {output_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hamming_binary(binarized_model, watermarked_text_binary):\n",
    "    \"\"\"\n",
    "    Detects if the provided binary string is watermarked, using hamming distance.\n",
    "    \"\"\"\n",
    "    if len(watermarked_text_binary) < binarized_model.n:\n",
    "        print(f\"appending {binarized_model.n - len(watermarked_text_binary)} zeros\")\n",
    "        watermarked_text_binary = torch.cat([watermarked_text_binary, torch.zeros(binarized_model.n - len(watermarked_text_binary))])\n",
    "\n",
    "    # wt(Px) < (1/2 - r^(-1/4)) * r, output 1, where P is the parity check matrix\n",
    "    parity_check_matrix = binarized_model.decoding_key[1]\n",
    "    r = parity_check_matrix.shape[0]\n",
    "    \n",
    "    # compute Px\n",
    "    Px = parity_check_matrix @ watermarked_text_binary\n",
    "    \n",
    "    # Calculate the hamming weight for values in {-1, 1}\n",
    "    # First convert from {-1, 1} to {0, 1} representation\n",
    "    Px_binary = (Px + 1) / 2\n",
    "    hamming_weight = np.sum(Px_binary)\n",
    "    \n",
    "    threshold = (1/2 - r**(-1/4)) * r\n",
    "    # if below threshold, then detection\n",
    "    result = hamming_weight < threshold\n",
    "    \n",
    "    return threshold, hamming_weight, result\n",
    "\n",
    "def detect_hamming_text(binarized_model, watermarked_text):\n",
    "    \"\"\"\n",
    "    Detects if the provided text is watermarked, using hamming distance.\n",
    "    \"\"\"\n",
    "    # convert watermarked_text to binary string using encoding\n",
    "    watermarked_text_binary = ''.join([binarized_model.encoding[token_id] for token_id in watermarked_text])\n",
    "    watermarked_text_binary = torch.tensor([int(bit) for bit in watermarked_text_binary], dtype=float)\n",
    "    watermarked_text_binary = 2 * watermarked_text_binary - 1\n",
    "\n",
    "    return detect_hamming_binary(binarized_model, watermarked_text_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending 4 zeros\n",
      "493.42963641011494\n",
      "738.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "threshold, hamming_weight, result = detect_hamming_text(binarized_model, output_tokens)\n",
    "print(threshold)\n",
    "print(hamming_weight)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_watermarked_text_to_binary(binarized_model, watermarked_text):\n",
    "    watermarked_text_binary = ''.join([binarized_model.encoding[token_id] for token_id in watermarked_text])\n",
    "    watermarked_text_binary = torch.tensor([int(bit) for bit in watermarked_text_binary], dtype=float)\n",
    "    watermarked_text_binary = 2 * watermarked_text_binary - 1\n",
    "    return watermarked_text_binary\n",
    "\n",
    "def corrupt_watermarked_text(binarized_model, watermarked_text, corruption_rate=0.1):\n",
    "    \"\"\"\n",
    "    Randomly flips bits in the binary representation of watermarked text.\n",
    "    \n",
    "    Args:\n",
    "        binarized_model: The binarized model containing encoding information.\n",
    "        watermarked_text: List of token IDs to be corrupted.\n",
    "        corruption_rate: Probability of flipping each bit (between 0 and 1).\n",
    "        \n",
    "    Returns:\n",
    "        Corrupted binary tensor with values in {-1, 1}.\n",
    "    \"\"\"\n",
    "    # Convert the watermarked text to binary format\n",
    "    watermarked_text_binary = convert_watermarked_text_to_binary(binarized_model, watermarked_text)\n",
    "    \n",
    "    # Create a mask of bits to flip based on the corruption rate\n",
    "    num_bits = len(watermarked_text_binary)\n",
    "    flip_mask = torch.rand(num_bits) < corruption_rate\n",
    "    \n",
    "    # Flip the selected bits (multiply by -1 since values are {-1, 1})\n",
    "    watermarked_text_binary[flip_mask] *= -1\n",
    "    \n",
    "    return watermarked_text_binary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corruptions: 422.0\n",
      "length: 2044\n"
     ]
    }
   ],
   "source": [
    "watermarked_text_binary = convert_watermarked_text_to_binary(binarized_model, output_tokens)\n",
    "corrupted_watermarked_text_binary = corrupt_watermarked_text(binarized_model, output_tokens)\n",
    "print(f\"corruptions: {torch.sum(torch.abs(watermarked_text_binary - corrupted_watermarked_text_binary))}\")\n",
    "print(f\"length: {len(watermarked_text_binary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# compute average detection rate\n",
    "corruption_rates = np.arange(0, 1, 0.1)\n",
    "detection_rates = []\n",
    "detection_rates_std = []\n",
    "for corruption_rate in corruption_rates:\n",
    "    detection_rate = []\n",
    "    for i in range(1000):\n",
    "        corrupted_watermarked_text_binary = corrupt_watermarked_text(binarized_model, output_tokens, corruption_rate)\n",
    "        threshold,= detect_hamming_binary(binarized_model, corrupted_watermarked_text_binary)\n",
    "        detection_rate.append(detection_result)\n",
    "    detection_rates.append(np.mean(detection_rate))\n",
    "    detection_rates_std.append(np.std(detection_rate))\n",
    "plt.plot(corruption_rates, detection_rates)\n",
    "plt.fill_between(corruption_rates, np.array(detection_rates) - np.array(detection_rates_std), np.array(detection_rates) + np.array(detection_rates_std), alpha=0.2)\n",
    "plt.xlabel(\"Corruption Rate\")\n",
    "plt.ylabel(\"Detection Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 493.42963641011494\n",
      "hamming_weight: 773.0\n",
      "result: False\n"
     ]
    }
   ],
   "source": [
    "# generate random binary string\n",
    "random_binary_string = torch.rand(n)\n",
    "random_binary_string[random_binary_string < 0.5] = -1\n",
    "random_binary_string[random_binary_string >= 0.5] = 1\n",
    "threshold, hamming_weight, result = detect_hamming_binary(binarized_model, random_binary_string)\n",
    "print(f\"threshold: {threshold}\")\n",
    "print(f\"hamming_weight: {hamming_weight}\")\n",
    "print(f\"result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
